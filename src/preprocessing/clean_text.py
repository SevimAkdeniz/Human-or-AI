import pandas as pd
import re
import os
from sklearn.utils import shuffle
import nltk
from nltk.corpus import stopwords 

# NLTK ve STOP_WORDS indirme/tanÄ±mlama kÄ±smÄ± aynÄ± kaldÄ±.
try:
    stopwords.words('english')
except LookupError:
    nltk.download('stopwords')

STOP_WORDS = set(stopwords.words('english'))

HUMAN_PATH = "dataset/human/human_augmented.csv"
AI_PATH = "dataset/ai/merged.csv"
OUTPUT_PATH = "dataset/cleaned/cleaned_dataset_new.csv"


def clean_text(text: str) -> str:
    """Metin temizleme fonksiyonu (Son Agresif Versiyon)."""
    if not isinstance(text, str):
        return ""

    text = text.lower()
    text = re.sub(r"<.*?>", " ", text)
    text = re.sub(r"http\S+|www\.\S+", " ", text)
    text = re.sub(r"\(.*?\)", " ", text)
    
    # Rakamlar, noktalamalar, Ã¶zel karakterler temizlenir.
    text = re.sub(r'[^a-z\s]', ' ', text) 

    tokens = text.split()
    tokens = [word for word in tokens if word not in STOP_WORDS]
    text = " ".join(tokens)
    
    text = re.sub(r"\s+", " ", text).strip()
    
    return text


def load_and_clean(path, label):
    # ğŸš© KRÄ°TÄ°K NOKTA 1: Sadece 'text' kolonunu okuyarak olasÄ± diÄŸer kolon sÄ±zÄ±ntÄ±larÄ±nÄ± engelle
    # EÄŸer ham CSV'lerinizde baÅŸka kolonlar varsa, onlarÄ± gÃ¶rmezden gelir.
    df = pd.read_csv(path, usecols=['text'])
    
    # text kolonunu temizle
    df["text"] = df["text"].astype(str).apply(clean_text)
    df["label"] = label

    # boÅŸ veya Ã§ok kÄ±sa metinleri at
    df = df[df["text"].str.len() > 30]

    print(f"Loaded {label} data: {len(df)} rows.")
    return df


def main():
    print("ğŸ“¥ Importing raw datasets...")
    human_df = load_and_clean(HUMAN_PATH, "human")
    ai_df = load_and_clean(AI_PATH, "ai")

    print("ğŸ”„ Merging...")
    full_df = pd.concat([human_df, ai_df], ignore_index=True)
    
    # ğŸš© KRÄ°TÄ°K NOKTA 2: TÃ¼m kolonlarÄ± kontrol et (Sadece 'text' ve 'label' kalmalÄ±)
    if list(full_df.columns) != ['text', 'label']:
        print(f"âš ï¸ DÄ°KKAT: DataFrame'de beklenmedik kolonlar var: {list(full_df.columns)}")
        # Sadece gerekli kolonlarÄ± tutarak sÄ±zÄ±ntÄ± kaynaÄŸÄ±nÄ± ele (Ã–rn. eski bir index kolonu)
        full_df = full_df[['text', 'label']]
        print("Kolonlar sadece 'text' ve 'label' olarak filtrelendi.")


    print("ğŸ”€ Shuffling...")
    # KRÄ°TÄ°K NOKTA 3: shuffle sonrasÄ± index'leri sÄ±fÄ±rlamak
    full_df = shuffle(full_df).reset_index(drop=True)

    print("ğŸ“ Saving cleaned dataset...")
    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)
    
    # index=False ile kaydederek gereksiz index kolonlarÄ±nÄ±n oluÅŸmasÄ±nÄ± engelle
    full_df.to_csv(OUTPUT_PATH, index=False)

    print("\nğŸ‰ SUCCESS! Cleaned dataset created:")
    print(f"  â†’ {OUTPUT_PATH}")
    print(f"  Total rows: {len(full_df)}")
    print(f"  Final columns: {list(full_df.columns)}") # Son kontrol

if __name__ == "__main__":
    main()